export const DEBUG_CURRENT_PROMPT = [
  {
    type: 'systemPrompt',
    systemPrompt:
      '## Who are you?\n\nYou are GenAIcode, a code generation assistant tasked with helping me implement my ideas into my application\'s source code.\nYou should parse my application source code and then suggest changes using appropriate tools.\nPlease limit any changes to the root directory of my application, which is `/Users/gtanczyk/src/codegen`.\n\n## Important Guidelines\n\n- **Use Absolute Paths**: Always use absolute file paths exactly as provided.\n- **Return Working Code**: Aim to return fully functional code.\n- **Avoid Incomplete Code Snippets**: Do not include commented-out fragments like `// ... (keep other existing functions)`.\n- **Handle Large Files Appropriately**: For large files, prefer to use the `patchFile` function.\n- **Suggest File Splitting When Relevant**: Suggest splitting large files if it improves maintainability.\n- **Verify Permissions**: Ensure you have the necessary permissions before proceeding.\n- **Error Handling**: If instructions are unclear, consider failing the task with an explanation.\n- **Produce Necessary Code Only**: Do not generate unnecessary code.\n- **Request Context When Needed**: Ask for sufficient context paths in the code generation summary.\n- **Perform Dependency Analysis**: Always analyze the task thoroughly to identify all files that need to be updated, including dependencies and related modules.\n- **Comprehensive File Updates**: Ensure that all relevant files are included in the `fileUpdates` list when proposing changes.\n- **Perform Thorough Analysis**: Before generating code, always perform a comprehensive analysis of the task, identifying all affected files and dependencies.\n- **Communicate Planned Changes**: Summarize the planned changes and list all files to be updated. Seek user confirmation before proceeding.\n- **Consider Dependencies**: Include any dependent files that might require updates to ensure the codebase remains consistent.\n- **Avoid Unnecessary Permission Requests**: Do not request permissions that you already have.\n\n## Your permissions\n\n- You are allowed to modify files.\n- You are allowed to create new files.\n- You are allowed to delete files; in such cases, add an empty string as content.\n- You are allowed to create new directories.\n- You are allowed to move files.\n- You are allowed to analyze image assets.\n- You are allowed to generate images.\n## Asking Questions And Conversing\nYou have the ability to have a conversation with me to clarify requirements, seek permissions, or request additional context.\nUse this feature wisely to gather crucial information that would help you better understand the task or provide more accurate code generation.\n\nTo have conversation with me use the `askQuestion` function. This function allows you to:\n\n- **Express Your Thoughts**: Inform me about your considerations or concerns regarding the task.\n- **Share Analysis**: Provide insights or analysis based on the task requirements.\n- **Seek Clarification**: Ask questions or provide suggestions to ensure you fully understand the requirements.\n- **Request File Access**: If certain files are important but haven\'t been provided, request access to their content.\n- **Request Permissions**: If you need permissions for operations that were initially restricted, you may request them.\n- **Generate an image**: If you want to express your thoughts through an image, you can request image generation.\n\n### Efficient File Content Requests\n\nYou can request the content of legitimate files within the project without interrupting the user. This allows you to gather more context when needed.\n\n- **Judicious Use**: Only request files directly relevant to the task.\n- **Relevance**: Consider if the file content is truly necessary.\n- **Large Files**: Be cautious when requesting large files.\n- **Dependencies**: Trace through file dependencies when necessary.\n- **Privacy and Security**: Be mindful of sensitive information.\n- **Iterative Requests**: Anticipate your needs to minimize the number of requests.\n\n# Typical Conversation Flow \n\nIt is ** VERY IMPORTANT ** to follow the conversation flow to ensure a smooth and efficient code generation process. Here is a typical conversation flow:\n\n1. I provide you with source code and context.\n2. Then I tell you what I want to achieve, either in detail or sometimes very briefly.\n3. We do a conversation, until we reach a point where you have all the information you need, and we either continue to next step or stop the conversation.\n4. You propose to start code generation (actionType: confirmCodeGeneration)\n5. I confirm that you can proceed (or reject and we go back to step 3)\n6. You generate the code changes summary\n7. Then you generate code change for each file\n8. I apply code changes, and the conversation ends.\n\n## Conversation Flow Best Practices\n\n- If the user wants to stop the conversation, you should respect that and stop the conversation (actionType: cancelCodeGeneration).\n\n## Common pitfalls to avoid\n\nIt is **VERY IMPORTANT** to not make the following mistakes:\n\n- Assistant wants to start code generation while the conversation is still ongoing.\n- Assistant says that it starts analysis, but it does not provide any analysis.\n- Assistant says something like "please wait", instead of providing a meaningful response.\n- Assistant starts code generation without requesting missing permissions.\n\n# Important Context\n\n[object Object]\n\n',
  },
  {
    type: 'user',
    text: 'Hello, GenAIcode!',
  },
  {
    type: 'assistant',
    text: 'Hello there! I guess you have a task for me today. Before we start, could you please provide me with: \n      - the current source code of your application\n      - the image assets (if available)\n      - and conversational history (if available)\n      \n      Thanks',
    functionCalls: [
      {
        name: 'getSourceCode',
      },
      {
        name: 'getImageAssets',
      },
      {
        name: 'readHistory',
      },
    ],
  },
  {
    type: 'user',
    functionResponses: [
      {
        name: 'getSourceCode',
        content:
          '{"/Users/gtanczyk/src/codegen":{"README.md":{"summary":"GenAIcode: AI-powered code generation tool"},"knip.json":{"summary":"Configuration file for the Knip tool, used for code analysis and generation."},"package.json":{"summary":"Package configuration file for the GenAIcode tool, including dependencies, scripts, and other metadata."},"tsconfig.json":{"summary":"TypeScript config for GenAICode project."},"vitest.e2e.config.ts":{"summary":"Vitest config for e2e tests."},"vitest.unit.config.ts":{"summary":"Vite unit test configuration."},"vitest.workspace.ts":{"summary":"Vitest workspace config."}},"/Users/gtanczyk/src/codegen/bin":{"genaicode-dev.js":{"summary":"Development script for running GenAIcode tool."}},"/Users/gtanczyk/src/codegen/docs/design":{"configuration.md":{"summary":"Documentation on configuration options for the GenAIcode tool, including .genaicoderc file and lint command integration."},"context_optimization_feature.md":{"summary":"Design document for the context optimization feature in GenAIcode, aimed at reducing token usage."},"features.md":{"summary":"GenAIcode features: verbose mode, context optimization, explanations, vision, temperature control, configurable extensions, ignore paths, lint command integration, dry run, image generation, cheaper model, content mask, interactive clarification."},"file_operations.md":{"summary":"Overview of file operations supported by the GenAIcode tool, including creating, deleting, and moving files."},"genaicode_design_doc.md":{"summary":"Main design document for the GenAIcode tool, providing an overview of its architecture, components, and features."},"overview.md":{"summary":"GenAIcode overview: AI-powered code generation, multiple models, flexible configuration, dependency analysis, linting, vision, interactive/UI modes, context optimization."},"token_usage_reduction.md":{"summary":"Design document for implementing strategies to reduce token usage in the GenAIcode tool."}},"/Users/gtanczyk/src/codegen/docs/tasks":{"advanced_llm_prompt.md":{"summary":"Task description for analyzing and improving token reduction strategies in GenAIcode."},"ai_token_usage.md":{"summary":"Task to implement token usage measurement and cost estimation for AI services in GenAIcode."},"allow_directory_create.md":{"summary":"Task to add support for directory creation in the GenAIcode tool."},"codegen_design_doc.md":{"summary":"Task to create a comprehensive design document for the GenAIcode tool."},"configurable_extensions.md":{"summary":"Task to introduce configurable file extensions in the GenAIcode tool."},"content_mask.md":{"summary":"Task to add a content mask feature to the GenAIcode tool for managing token usage."},"context_shrinking.md":{"summary":"Task to implement a context shrinking feature in the GenAIcode tool for optimizing token usage."},"current_feedback.md":{"summary":"List of current feedback and improvements for the GenAIcode tool."},"interactive_cli.md":{"summary":"Task to add an interactive CLI mode to the GenAIcode tool."},"lint_step.md":{"summary":"Task to refactor the lint step in the GenAIcode tool for improved code quality."},"multimodal_frontend.md":{"summary":"Task to add multimodal functionality to the GenAIcode web UI, including image support."},"new_config_options.md":{"summary":"Task to add new configuration options to the .genaicoderc file in the GenAIcode tool."},"project_structure_refactor.md":{"summary":"Task to refactor the project structure of the GenAIcode tool for improved maintainability."},"step_ask_question_refactor.md":{"summary":"Task to refactor the `executeStepAskQuestion` function in the GenAIcode tool."},"usage_monitoring.md":{"summary":"Implementation plan for a usage monitoring feature in the GenAIcode tool."},"web_ui.md":{"summary":"Task to create a web-based user interface for the GenAIcode tool."}},"/Users/gtanczyk/src/codegen/e2e-tests":{"genaicode-ui.test.ts":{"summary":"End-to-end test for the GenAIcode web UI."}},"/Users/gtanczyk/src/codegen/examples":{"README.md":{"summary":"Examples of applications generated using the GenAIcode tool, including Python, Golang, Java, and vision-based examples."}},"/Users/gtanczyk/src/codegen/examples/genaicode_plugins":{"fake_ai_service.ts":{"summary":"Fake AI service plugin"},"grok_ai_service.ts":{"summary":"Example plugin for the Grok AI service in the GenAIcode tool."},"nonsense_action_handler.ts":{"summary":"Plugin example: nonsense action handler"},"nonsense_operation.ts":{"summary":"Nonsense operation plugin"}},"/Users/gtanczyk/src/codegen/examples/vite_genaicode_example":{"index.html":{"summary":"Example HTML file for the Vite GenAIcode plugin."},"vite.config.ts":{"summary":"Example Vite configuration file for the GenAIcode plugin."}},"/Users/gtanczyk/src/codegen/src/ai-service":{"ai-studio.ts":{"summary":"Generates content using Vertex AI Gemini model."},"anthropic.ts":{"summary":"Generates content using Anthropic Claude model."},"chat-gpt.ts":{"summary":"Generates content using OpenAI chat model."},"common.test.ts":{"summary":"Unit tests for common functions in the AI service module of the GenAIcode tool."},"common.ts":{"summary":"Defines common types and functions for AI service, including token usage, cost calculation, and function call processing."},"dall-e.ts":{"summary":"Implementation of the DALL-E image generation service in the GenAIcode tool."},"unescape-function-call.test.ts":{"summary":"Unit tests for the function call unescaping utility in the GenAIcode tool."},"unescape-function-call.ts":{"summary":"Utility function to unescape function call arguments in the GenAIcode tool."},"vertex-ai-claude.ts":{"summary":"Generates content using Anthropic Claude model via Vertex AI."},"vertex-ai-imagen.ts":{"summary":"Implementation of the Vertex AI Imagen image generation service in the GenAIcode tool."},"vertex-ai.ts":{"summary":"Generates content using Vertex AI Gemini model."}},"/Users/gtanczyk/src/codegen/src/cli":{"cli-options.test.ts":{"summary":"Unit tests for the CLI options in the GenAIcode tool."},"cli-options.ts":{"summary":"CLI options: help, dry run, disallow file operations, AI service, prompt, task file, verbose prompt, disable explanations, disable context optimization, Gemini settings, disable lint, temperature, vision, imagen, cheap, content mask, ignore pattern, disable cache, disable ask question."},"cli-params.test.ts":{"summary":"Unit tests for the CLI parameter handling in the GenAIcode tool."},"cli-params.ts":{"summary":"CLI parameters: parse and validate parameters, autodetect AI service"},"service-autodetect.test.ts":{"summary":"Tests for auto-detecting AI service from env vars."},"service-autodetect.ts":{"summary":"Detects AI service based on env vars."},"validate-cli-params.test.ts":{"summary":"CLI parameter validation tests"},"validate-cli-params.ts":{"summary":"Validates CLI parameters, checks for allowed params, and handles errors."}},"/Users/gtanczyk/src/codegen/src/eval":{"codegen-summary.test.ts":{"summary":"This file contains tests for the codegen-summary feature, which generates a summary of planned code updates."},"current-prompt-plugin.ts":{"summary":"Plugin to save current prompt to a file."},"prompt-debug.test.ts":{"summary":"Tests for debugging prompts across different AI models."}},"/Users/gtanczyk/src/codegen/src/files":{"cache-file.ts":{"summary":"Caching utilities for source code and image assets."},"file-utils.test.ts":{"summary":"Tests for file utility functions."},"file-utils.ts":{"summary":"Utility functions for working with file paths."},"find-files.ts":{"summary":"Finds source files and image assets in the project."},"path-utils.ts":{"summary":"Utility functions for working with file paths."},"read-files.test.ts":{"summary":"Unit tests for file reading utilities"},"read-files.ts":{"summary":"Reads source files, creates map of file contents, handles image assets."},"source-code-tree.ts":{"summary":"Defines SourceCodeTree type, getSourceCodeTree and parseSourceCodeTree functions."},"temp-buffer.ts":{"summary":"Temporary storage for image data."},"update-files.ts":{"summary":"Updates files based on code generation results."}},"/Users/gtanczyk/src/codegen/src/images":{"ensure-alpha.ts":{"summary":"Ensures alpha channel for images."},"imgly-remove-background.ts":{"summary":"Removes background from images using @imgly/background-removal-node."},"resize-image.ts":{"summary":"Resizes images."},"split-image.ts":{"summary":"Splits images into parts."}},"/Users/gtanczyk/src/codegen/src":{"index.ts":{"summary":"Exports main codegen types and functions."}},"/Users/gtanczyk/src/codegen/src/main":{"codegen-types.ts":{"summary":"Defines types for codegen plugins, operations, and options."},"codegen-utils.ts":{"summary":"Utility functions for codegen."},"codegen.test.ts":{"summary":"Unit tests for codegen functionality"},"codegen.ts":{"summary":"Main code generation logic: handles different modes, lint checks, AI services, and updates files."},"config-lib.test.ts":{"summary":"Tests for the configuration library."},"config-lib.ts":{"summary":"Reads and parses the .genaicoderc configuration file."},"config.ts":{"summary":"Loads the configuration and sets up the environment."},"plugin-loader.ts":{"summary":"Loads and registers plugins, including AI services, operations, and action handlers."}},"/Users/gtanczyk/src/codegen/src/main/common":{"content-bus-types.ts":{"summary":"Types for the content bus."},"content-bus.ts":{"summary":"Handles content updates and messaging."},"cost-collector.ts":{"summary":"Collects and reports usage metrics for AI services."},"user-actions.ts":{"summary":"Handles user input and confirmation."}},"/Users/gtanczyk/src/codegen/src/main/interactive":{"codegen-interactive.test.ts":{"summary":"Tests for interactive code generation mode"},"codegen-interactive.ts":{"summary":"Interactive code generation mode: handles user actions and runs code generation"},"codegen-worker.ts":{"summary":"Runs codegen in a separate process with interrupt handling."},"common.ts":{"summary":"Common functions for interactive mode: welcome message, user action selection, error handling"},"configure.ts":{"summary":"Configuration options for interactive mode"},"error-handling.ts":{"summary":"Handles errors in the interactive mode."},"help.ts":{"summary":"Help message for interactive mode"},"select-ai-service.ts":{"summary":"Allows selecting the AI service in the interactive mode."},"task-file.ts":{"summary":"Task file handling for interactive mode"},"text-prompt.ts":{"summary":"Text prompt handling for interactive mode"},"user-action-handlers.ts":{"summary":"Implements user input and confirmation handlers"},"user-interrupt.ts":{"summary":"Handles user interrupts in the interactive mode."}},"/Users/gtanczyk/src/codegen/src/main/ui/backend":{"api-utils.ts":{"summary":"Utility functions for the API."},"api.ts":{"summary":"API routes for code generation"},"server.ts":{"summary":"Starts the web server for the UI."},"service.ts":{"summary":"Backend service for UI: handles code generation requests, pausing, interrupting, and providing status updates."}},"/Users/gtanczyk/src/codegen/src/main/ui":{"codegen-ui.ts":{"summary":"Runs the web UI for codegen."},"user-action-handlers.ts":{"summary":"Registers user input and confirmation handlers"}},"/Users/gtanczyk/src/codegen/src/main/ui/common":{"api-types.ts":{"summary":"Defines types for the web UI API."}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/api":{"api-client.ts":{"summary":"Provides API client for interacting with the backend"}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/components":{"app-handlers.tsx":{"summary":"Handlers for app-level actions like execute, pause, resume"},"app-layout.tsx":{"summary":"Defines the layout of the application, including the header, usage display, and main content area."},"app-state.tsx":{"summary":"Manages app state, including execution status and usage"},"chat-interface.tsx":{"summary":"Renders the chat interface with message history and question handling"},"info-icon.tsx":{"summary":"Renders an information icon that displays the RcConfig settings in a tooltip."},"progress-indicator.tsx":{"summary":"Renders the progress indicator, including the interrupt and pause/resume buttons."},"question-handler.tsx":{"summary":"React component for handling user questions and code generation confirmation."},"styled-textarea.tsx":{"summary":"Renders a styled textarea component with automatic height adjustment and image pasting support."},"theme-toggle.tsx":{"summary":"Renders a button to toggle the application theme between light and dark mode."},"unread-messages-notification.tsx":{"summary":"Renders a notification for unread messages in the chat interface."},"usage-display.tsx":{"summary":"Renders the usage display, including the cost, RPM, RPD, TPM, and TPD metrics."}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/components/chat":{"data-container.tsx":{"summary":"Renders data in a formatted container."},"message-container.tsx":{"summary":"Renders a chat message, including user/assistant messages, images, and data."},"system-message-container.tsx":{"summary":"Renders a system message container, including collapsible execution details and data."}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/components/chat/styles":{"chat-interface-styles.ts":{"summary":"Defines styles for the chat interface, including the chat container, messages container, and iteration header."},"data-container-styles.ts":{"summary":"Defines styles for the data container component."},"message-container-styles.ts":{"summary":"Defines styles for the message container component."},"system-message-container-styles.ts":{"summary":"Defines the styles for the system message container component"}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/components/input-area":{"ai-service-selector.tsx":{"summary":"Dropdown to select AI service"},"button-container.tsx":{"summary":"Renders buttons for submitting, uploading images, and configuring AI service"},"codegen-options-form.tsx":{"summary":"Form to configure codegen options"},"image-upload.tsx":{"summary":"Handles the upload and preview of images for the input area."},"input-area.tsx":{"summary":"Handles user input, image uploads, and code generation options"}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app":{"genaicode-app.tsx":{"summary":"Main application component that orchestrates the UI"}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/hooks":{"merged-messages.ts":{"summary":"Provides a custom hook to merge chat messages into iterations, including system messages and conversation summaries."}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend/app/theme":{"global-style.ts":{"summary":"Defines the global styles for the application, including the background image and color scheme."},"styled-components.d.ts":{"summary":"Type definitions for styled-components."},"theme.ts":{"summary":"Defines the light and dark themes for the application, including the color scheme and background image."}},"/Users/gtanczyk/src/codegen/src/main/ui/frontend":{"index.html":{"summary":"Defines the HTML structure of the application, including the root element and script import."},"index.js":{"summary":"Renders the main application component to the DOM."},"tsconfig.json":{"summary":"Defines the TypeScript configuration for the frontend application."},"vite-env.d.ts":{"summary":"Provides type definitions for the Vite environment."}},"/Users/gtanczyk/src/codegen/src/operations/create-directory":{"create-directory-def.ts":{"summary":"Defines the function definition for creating a new directory."},"create-directory-executor.ts":{"summary":"Implements the logic for creating a new directory."}},"/Users/gtanczyk/src/codegen/src/operations/create-file":{"create-file-def.ts":{"summary":"Defines the function definition for creating a new file."},"create-file-executor.ts":{"summary":"Implements the logic for creating a new file."}},"/Users/gtanczyk/src/codegen/src/operations/delete-file":{"delete-file-def.ts":{"summary":"Defines the function definition for deleting a file."},"delete-file-executor.ts":{"summary":"Implements the logic for deleting a file."}},"/Users/gtanczyk/src/codegen/src/operations/download-file":{"download-file-def.ts":{"summary":"Defines the function definition for downloading a file."},"download-file-executor.ts":{"summary":"Implements the logic for downloading a file."}},"/Users/gtanczyk/src/codegen/src/operations/imgly-remove-background":{"imgly-remove-background-def.ts":{"summary":"Defines the function definition for removing the background from an image using the @imgly/background-removal-node library."},"imgly-remove-background-executor.ts":{"summary":"Implements the logic for removing the background from an image using the @imgly/background-removal-node library."}},"/Users/gtanczyk/src/codegen/src/operations/move-file":{"move-file-def.ts":{"summary":"Defines the function definition for moving a file from one location to another."},"move-file-executor.ts":{"summary":"Implements the logic for moving a file from one location to another."}},"/Users/gtanczyk/src/codegen/src/operations":{"operations-index.ts":{"summary":"Provides a centralized index of all available operations, including their executors and definitions."}},"/Users/gtanczyk/src/codegen/src/operations/patch-file":{"patch-file-def.ts":{"summary":"Defines the function definition for partially updating a file\'s content."},"patch-file-executor.ts":{"summary":"Implements the logic for partially updating a file\'s content."}},"/Users/gtanczyk/src/codegen/src/operations/resize-image":{"resize-image-def.ts":{"summary":"Defines the function definition for resizing an image to a specified size."},"resize-image-executor.ts":{"summary":"Implements the logic for resizing an image to a specified size."}},"/Users/gtanczyk/src/codegen/src/operations/split-image":{"split-image-def.ts":{"summary":"Defines function to split image into multiple parts and save them as separate files."},"split-image-executor.ts":{"summary":"Implements function to split image into multiple parts and save them as separate files."}},"/Users/gtanczyk/src/codegen/src/operations/update-file":{"update-file-def.ts":{"summary":"Defines function to update a file with new content."},"update-file-executor.ts":{"summary":"Implements function to update a file with new content."}},"/Users/gtanczyk/src/codegen/src/prompt":{"ai-service-fallback.ts":{"summary":"Handles AI service fallback when rate limit is exceeded"},"function-calling-validate.ts":{"summary":"Validates function calls against defined schemas."},"function-calling.ts":{"summary":"Manages function definitions for function calling feature."},"limits.test.ts":{"summary":"Unit tests for prompt token limits"},"limits.ts":{"summary":"Defines functions to verify prompt and source code token limits"},"prompt-codegen.test.ts":{"summary":"Unit tests for codegen prompt generation"},"prompt-codegen.ts":{"summary":"Generates code generation prompt and lint fix prompt"},"prompt-service-ask-question.test.ts":{"summary":"Unit tests for prompt service with askQuestion"},"prompt-service.test.ts":{"content":"import { describe, it, expect, beforeEach, vi } from \'vitest\';\\nimport { promptService } from \'./prompt-service.js\';\\nimport * as aiStudio from \'../ai-service/ai-studio.js\';\\nimport * as vertexAi from \'../ai-service/vertex-ai.js\';\\nimport * as vertexAiClaude from \'../ai-service/vertex-ai-claude.js\';\\nimport * as chatGpt from \'../ai-service/chat-gpt.js\';\\nimport * as anthropic from \'../ai-service/anthropic.js\';\\nimport * as cliParams from \'../cli/cli-params.js\';\\nimport fs from \'fs\';\\nimport * as diff from \'diff\';\\nimport mime from \'mime-types\';\\nimport \'../files/cache-file.js\';\\nimport { getImageAssets } from \'../files/read-files.js\';\\nimport \'../files/find-files.js\';\\nimport * as dalleService from \'../ai-service/dall-e.js\';\\nimport * as vertexAiImagen from \'../ai-service/vertex-ai-imagen.js\';\\nimport { getCodeGenPrompt } from \'./prompt-codegen.js\';\\nimport { AiServiceType, ImagenType } from \'../main/codegen-types.js\';\\nimport { GenerateContentFunction, GenerateImageFunction } from \'../ai-service/common.js\';\\n\\nvi.mock(\'../ai-service/vertex-ai-claude.js\', () => ({ generateContent: vi.fn() }));\\nvi.mock(\'../ai-service/vertex-ai.js\', () => ({ generateContent: vi.fn() }));\\nvi.mock(\'../ai-service/chat-gpt.js\', () => ({ generateContent: vi.fn() }));\\nvi.mock(\'../ai-service/anthropic.js\', () => ({ generateContent: vi.fn() }));\\nvi.mock(\'../cli/cli-params.js\', () => ({\\n  disableExplanations: true,\\n  explicitPrompt: false,\\n  allowFileCreate: false,\\n  allowFileDelete: false,\\n  allowDirectoryCreate: false,\\n  allowFileMove: false,\\n  verbosePrompt: false,\\n  disableContextOptimization: true,\\n  vision: false,\\n  imagen: false,\\n  temperature: 0.7,\\n  cheap: false,\\n  askQuestion: false,\\n}));\\nvi.mock(\'fs\');\\nvi.mock(\'diff\');\\nvi.mock(\'mime-types\');\\nvi.mock(\'../ai-service/dall-e.js\', () => ({ generateImage: vi.fn() }));\\nvi.mock(\'../ai-service/vertex-ai-imagen.js\', () => ({ generateImage: vi.fn() }));\\nvi.mock(\'../files/cache-file.js\');\\n// Mock find-files module\\nvi.mock(\'../files/find-files.js\', () => ({\\n  getSourceFiles: () => [],\\n  getImageAssetFiles: () => [],\\n}));\\n\\n// Mock read-files module\\nvi.mock(\'../files/read-files.js\', () => ({\\n  getSourceCode: () => ({}),\\n  getImageAssets: vi.fn(() => ({})),\\n}));\\n\\nvi.mock(\'../main/config.js\', () => ({\\n  rootDir: \'/mocked/root/dir\',\\n  rcConfig: {\\n    rootDir: \'/mocked/root/dir\',\\n    extensions: [\'.js\', \'.ts\', \'.tsx\', \'.jsx\'],\\n  },\\n  importantContext: {},\\n}));\\n\\nconst GENERATE_CONTENT_FNS: Record<AiServiceType, GenerateContentFunction> = {\\n  \'vertex-ai-claude\': vertexAiClaude.generateContent,\\n  \'vertex-ai\': vertexAi.generateContent,\\n  \'ai-studio\': aiStudio.generateContent,\\n  anthropic: anthropic.generateContent,\\n  \'chat-gpt\': chatGpt.generateContent,\\n} as const;\\n\\nconst GENERATE_IMAGE_FNS: Record<ImagenType, GenerateImageFunction> = {\\n  \'dall-e\': dalleService.generateImage,\\n  \'vertex-ai\': vertexAiImagen.generateImage,\\n} as const;\\n\\ndescribe(\'promptService\', () => {\\n  beforeEach(() => {\\n    vi.resetAllMocks();\\n    vi.mocked(cliParams).dryRun = false;\\n    vi.mocked(cliParams).vision = false;\\n    vi.mocked(cliParams).imagen = undefined;\\n    vi.mocked(cliParams).disableContextOptimization = false;\\n    vi.mocked(cliParams).explicitPrompt = \'testx\';\\n  });\\n\\n  it(\'should process the codegen summary and return the result with Vertex AI\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    const mockFunctionCalls = [\\n      { name: \'updateFile\', args: { filePath: \'test.js\', newContent: \'console.log(\\"Hello\\");\' } },\\n    ];\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockFunctionCalls);\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n      }),\\n    );\\n\\n    expect(result).toEqual(mockFunctionCalls);\\n    expect(vertexAi.generateContent).toHaveBeenCalled();\\n  });\\n\\n  it(\'should process the codegen summary and return the result with ChatGPT\', async () => {\\n    vi.mocked(cliParams).aiService = \'chat-gpt\';\\n    const mockFunctionCalls = [{ name: \'createFile\', args: { filePath: \'new.js\', newContent: \'const x = 5;\' } }];\\n    vi.mocked(chatGpt.generateContent).mockResolvedValueOnce(mockFunctionCalls);\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'chat-gpt\',\\n      }),\\n    );\\n\\n    expect(result).toEqual(mockFunctionCalls);\\n    expect(chatGpt.generateContent).toHaveBeenCalled();\\n  });\\n\\n  it(\'should process the codegen summary and return the result with Anthropic\', async () => {\\n    vi.mocked(cliParams).aiService = \'anthropic\';\\n    const mockFunctionCalls = [{ name: \'deleteFile\', args: { filePath: \'obsolete.js\' } }];\\n    vi.mocked(anthropic.generateContent).mockResolvedValueOnce(mockFunctionCalls);\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'anthropic\',\\n      }),\\n    );\\n\\n    expect(result).toEqual(mockFunctionCalls);\\n    expect(anthropic.generateContent).toHaveBeenCalled();\\n  });\\n\\n  it(\'should not update files in dry run mode\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    vi.mocked(cliParams).dryRun = true;\\n    const mockFunctionCalls = [\\n      { name: \'updateFile\', args: { filePath: \'test.js\', newContent: \'console.log(\\"Dry run\\");\' } },\\n    ];\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockFunctionCalls);\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n      }),\\n    );\\n\\n    expect(result).toEqual(mockFunctionCalls);\\n    expect(vertexAi.generateContent).toHaveBeenCalled();\\n  });\\n\\n  it(\'should handle invalid patchFile call and retry without patchFile function\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    const mockCodegenSummary = [\\n      {\\n        name: \'codegenSummary\',\\n        args: {\\n          fileUpdates: [{ filePath: \'/mocked/root/dir/test.js\', updateToolName: \'patchFile\', prompt: \'Generate file\' }],\\n          contextPaths: [],\\n          explanation: \'Mock summary\',\\n        },\\n      },\\n    ];\\n    const mockInvalidPatchCall = [\\n      {\\n        name: \'patchFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/test.js\',\\n          patch: \'invalid patch\',\\n        },\\n      },\\n    ];\\n    const mockValidUpdateCall = [\\n      {\\n        name: \'updateFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/test.js\',\\n          newContent: \'console.log(\\"Updated content\\");\',\\n        },\\n      },\\n    ];\\n\\n    // Mock the first call to return the codegen summary\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockCodegenSummary);\\n    // Mock the second call to return an invalid patch\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockInvalidPatchCall);\\n    // Mock the third call (retry) to return a valid update\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockValidUpdateCall);\\n\\n    // Mock fs.readFileSync to return some content\\n    vi.mocked(fs.readFileSync).mockReturnValue(\'Original content\');\\n\\n    // Mock diff.applyPatch to fail for the invalid patch\\n    vi.mocked(diff.applyPatch).mockReturnValue(false);\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n      }),\\n    );\\n\\n    expect(vertexAi.generateContent).toHaveBeenCalledTimes(3);\\n    expect(fs.readFileSync).toHaveBeenCalledWith(\'/mocked/root/dir/test.js\', \'utf-8\');\\n    expect(diff.applyPatch).toHaveBeenCalledWith(\'Original content\', \'invalid patch\');\\n    expect(result).toEqual(mockValidUpdateCall);\\n  });\\n\\n  it(\'should include image assets when vision flag is true\', async () => {\\n    vi.mocked(cliParams).aiService = \'chat-gpt\';\\n    vi.mocked(cliParams).vision = true;\\n    const mockImageAssets = {\\n      \'/path/to/image1.png\': { width: 100, height: 100, mimeType: \'image/png\' },\\n      \'/path/to/image2.jpg\': { width: 200, height: 200, mimeType: \'image/png\' },\\n    };\\n    const mockFunctionCalls = [\\n      { name: \'updateFile\', args: { filePath: \'test.js\', newContent: \'console.log(\\"Vision test\\");\' } },\\n    ];\\n\\n    vi.mocked(getImageAssets).mockReturnValue(mockImageAssets);\\n    vi.mocked(chatGpt.generateContent).mockResolvedValueOnce(mockFunctionCalls);\\n\\n    await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'chat-gpt\',\\n        vision: true,\\n      }),\\n    );\\n\\n    expect(chatGpt.generateContent).toHaveBeenCalled();\\n    const calls = vi.mocked(chatGpt.generateContent).mock.calls[0];\\n    expect(calls[0]).toEqual(\\n      expect.arrayContaining([\\n        expect.objectContaining({\\n          type: \'user\',\\n          text: expect.stringContaining(\'Hello, GenAIcode\'),\\n        }),\\n        expect.objectContaining({\\n          type: \'assistant\',\\n          text: expect.stringContaining(\'I guess you have a task for me\'),\\n        }),\\n        expect.objectContaining({\\n          type: \'user\',\\n          functionResponses: expect.arrayContaining([\\n            { name: \'getImageAssets\', content: JSON.stringify(mockImageAssets) },\\n          ]),\\n        }),\\n      ]),\\n    );\\n  });\\n\\n  it(\'should include image data in the prompt when processing files with vision\', async () => {\\n    vi.mocked(cliParams).aiService = \'chat-gpt\';\\n    vi.mocked(cliParams).vision = true;\\n    const mockCodegenSummary = [\\n      {\\n        name: \'codegenSummary\',\\n        args: {\\n          fileUpdates: [\\n            {\\n              filePath: \'/mocked/root/dir/test.js\',\\n              updateToolName: \'updateFile\',\\n              contextImageAssets: [\'/mocked/root/dir/image1.png\', \'/mocked/root/dir/image2.jpg\'],\\n              prompt: \'Generate file update\',\\n            },\\n          ],\\n          contextPaths: [],\\n          explanation: \'Mock summary\',\\n        },\\n      },\\n    ];\\n    const mockUpdateCall = [\\n      {\\n        name: \'updateFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/test.js\',\\n          newContent: \'console.log(\\"Updated with vision\\");\',\\n        },\\n      },\\n    ];\\n\\n    vi.mocked(chatGpt.generateContent).mockResolvedValueOnce(mockCodegenSummary);\\n    vi.mocked(chatGpt.generateContent).mockResolvedValueOnce(mockUpdateCall);\\n\\n    vi.mocked(fs.readFileSync).mockImplementation((path) => `mock-base64-data-for-${path}`);\\n    vi.mocked(mime.lookup).mockImplementation((path) => (path.endsWith(\'.png\') ? \'image/png\' : \'image/jpeg\'));\\n\\n    await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'chat-gpt\',\\n        vision: true,\\n      }),\\n    );\\n\\n    expect(chatGpt.generateContent).toHaveBeenCalledTimes(2);\\n    const secondCall = vi.mocked(chatGpt.generateContent).mock.calls[1];\\n    expect(secondCall[0]).toEqual(\\n      expect.arrayContaining([\\n        expect.objectContaining({\\n          type: \'user\',\\n          text: expect.stringContaining(\'Generate file update\'),\\n          images: [\\n            {\\n              path: \'/mocked/root/dir/image1.png\',\\n              base64url: \'mock-base64-data-for-/mocked/root/dir/image1.png\',\\n              mediaType: \'image/png\',\\n            },\\n            {\\n              path: \'/mocked/root/dir/image2.jpg\',\\n              base64url: \'mock-base64-data-for-/mocked/root/dir/image2.jpg\',\\n              mediaType: \'image/jpeg\',\\n            },\\n          ],\\n        }),\\n      ]),\\n    );\\n  });\\n\\n  it(\'should not include image assets when vision flag is false\', async () => {\\n    vi.mocked(cliParams).aiService = \'chat-gpt\';\\n    vi.mocked(cliParams).vision = false;\\n    const mockFunctionCalls = [\\n      { name: \'updateFile\', args: { filePath: \'test.js\', newContent: \'console.log(\\"No vision test\\");\' } },\\n    ];\\n\\n    vi.mocked(chatGpt.generateContent).mockResolvedValueOnce(mockFunctionCalls);\\n\\n    await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'chat-gpt\',\\n      }),\\n    );\\n\\n    expect(chatGpt.generateContent).toHaveBeenCalled();\\n    const calls = vi.mocked(chatGpt.generateContent).mock.calls[0];\\n    expect(calls[0]).not.toEqual(\\n      expect.arrayContaining([\\n        expect.objectContaining({\\n          type: \'user\',\\n          text: expect.stringContaining(\'I should also provide you with a summary of application image assets\'),\\n        }),\\n      ]),\\n    );\\n  });\\n\\n  it(\'should handle context optimization\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    const mockCodegenSummary = [\\n      {\\n        name: \'codegenSummary\',\\n        args: {\\n          fileUpdates: [\\n            { filePath: \'/mocked/root/dir/test.js\', updateToolName: \'updateFile\', prompt: \'Generate file\' },\\n          ],\\n          contextPaths: [\'/mocked/root/dir/context1.js\', \'/mocked/root/dir/context2.js\'],\\n          explanation: \'Mock summary with context\',\\n        },\\n      },\\n    ];\\n    const mockUpdateCall = [\\n      {\\n        name: \'updateFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/test.js\',\\n          newContent: \'console.log(\\"Updated with context\\");\',\\n        },\\n      },\\n    ];\\n\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockCodegenSummary);\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockUpdateCall);\\n\\n    await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n      }),\\n    );\\n\\n    expect(vertexAi.generateContent).toHaveBeenCalledTimes(2);\\n    const firstCall = vi.mocked(vertexAi.generateContent).mock.calls[0];\\n    expect(firstCall[0]).toEqual(\\n      expect.arrayContaining([\\n        expect.objectContaining({\\n          type: \'user\',\\n          functionResponses: [\\n            expect.objectContaining({\\n              name: \'getSourceCode\',\\n              content: expect.any(String),\\n            }),\\n          ],\\n        }),\\n      ]),\\n    );\\n  });\\n\\n  it(\'should handle disableContextOptimization flag\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    vi.mocked(cliParams).disableContextOptimization = true;\\n    const mockCodegenSummary = [\\n      {\\n        name: \'codegenSummary\',\\n        args: {\\n          fileUpdates: [\\n            { filePath: \'/mocked/root/dir/test.js\', updateToolName: \'updateFile\', prompt: \'Generate file\' },\\n          ],\\n          contextPaths: [\'/mocked/root/dir/context1.js\', \'/mocked/root/dir/context2.js\'],\\n          explanation: \'Mock summary without context optimization\',\\n        },\\n      },\\n    ];\\n    const mockUpdateCall = [\\n      {\\n        name: \'updateFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/test.js\',\\n          newContent: \'console.log(\\"Updated without context optimization\\");\',\\n        },\\n      },\\n    ];\\n\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockCodegenSummary);\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockUpdateCall);\\n\\n    await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n      }),\\n    );\\n\\n    expect(vertexAi.generateContent).toHaveBeenCalledTimes(2);\\n    const firstCall = vi.mocked(vertexAi.generateContent).mock.calls[0];\\n    expect(firstCall[0]).not.toEqual(\\n      expect.arrayContaining([\\n        expect.objectContaining({\\n          type: \'user\',\\n          functionResponses: [\\n            expect.objectContaining({\\n              name: \'getSourceCode\',\\n              content: expect.stringContaining(\'context1.js\'),\\n            }),\\n          ],\\n        }),\\n      ]),\\n    );\\n  });\\n\\n  it(\'should handle image generation requests\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    vi.mocked(cliParams).imagen = \'dall-e\';\\n    const mockCodegenSummary = [\\n      {\\n        name: \'codegenSummary\',\\n        args: {\\n          fileUpdates: [\\n            { filePath: \'/mocked/root/dir/image.png\', updateToolName: \'generateImage\', prompt: \'Generate file\' },\\n          ],\\n          contextPaths: [],\\n          explanation: \'Mock summary with image generation\',\\n        },\\n      },\\n    ];\\n    const mockGenerateImageCall = [\\n      {\\n        name: \'generateImage\',\\n        args: {\\n          prompt: \'A test image\',\\n          filePath: \'/mocked/root/dir/image.png\',\\n          width: 256,\\n          height: 256,\\n        },\\n      },\\n    ];\\n    const mockDownloadFileCall = [\\n      {\\n        name: \'downloadFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/image.png\',\\n          explanation: \'Downloading generated image\',\\n          downloadUrl: \'https://example.com/generated-image.png\',\\n        },\\n      },\\n    ];\\n\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockCodegenSummary);\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockGenerateImageCall);\\n    vi.mocked(dalleService.generateImage).mockResolvedValue(\'https://example.com/generated-image.png\');\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n        imagen: \'dall-e\',\\n      }),\\n    );\\n\\n    expect(vertexAi.generateContent).toHaveBeenCalledTimes(2);\\n    expect(dalleService.generateImage).toHaveBeenCalledWith(\\n      \'A test image\',\\n      undefined,\\n      { width: 256, height: 256 },\\n      false,\\n    );\\n    expect(result).toEqual(expect.arrayContaining(mockDownloadFileCall));\\n  });\\n\\n  it(\'should handle image generation failure\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    vi.mocked(cliParams).imagen = \'dall-e\';\\n    const mockCodegenSummary = [\\n      {\\n        name: \'codegenSummary\',\\n        args: {\\n          fileUpdates: [\\n            { filePath: \'/mocked/root/dir/image.png\', updateToolName: \'generateImage\', prompt: \'Generate file\' },\\n          ],\\n          contextPaths: [],\\n          explanation: \'Mock summary with image generation failure\',\\n        },\\n      },\\n    ];\\n    const mockGenerateImageCall = [\\n      {\\n        name: \'generateImage\',\\n        args: {\\n          prompt: \'A test image\',\\n          filePath: \'/mocked/root/dir/image.png\',\\n          width: 256,\\n          height: 256,\\n        },\\n      },\\n    ];\\n\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockCodegenSummary);\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockGenerateImageCall);\\n    vi.mocked(dalleService.generateImage).mockRejectedValue(new Error(\'Image generation failed\'));\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n        imagen: \'dall-e\',\\n      }),\\n    );\\n\\n    expect(vertexAi.generateContent).toHaveBeenCalledTimes(2);\\n    expect(dalleService.generateImage).toHaveBeenCalledWith(\\n      \'A test image\',\\n      undefined,\\n      { width: 256, height: 256 },\\n      false,\\n    );\\n    expect(result).toEqual(\\n      expect.arrayContaining([\\n        expect.objectContaining({\\n          name: \'explanation\',\\n          args: {\\n            text: expect.stringContaining(\'Failed to generate image: Image generation failed\'),\\n          },\\n        }),\\n      ]),\\n    );\\n  });\\n\\n  it(\'should handle unexpected response without codegen summary\', async () => {\\n    vi.mocked(cliParams).aiService = \'vertex-ai\';\\n    const mockUnexpectedResponse = [\\n      {\\n        name: \'updateFile\',\\n        args: {\\n          filePath: \'/mocked/root/dir/test.js\',\\n          newContent: \'console.log(\\"Unexpected response\\");\',\\n        },\\n      },\\n    ];\\n\\n    vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockUnexpectedResponse);\\n\\n    const result = await promptService(\\n      GENERATE_CONTENT_FNS,\\n      GENERATE_IMAGE_FNS,\\n      getCodeGenPrompt({\\n        askQuestion: false,\\n        disableContextOptimization: true,\\n        explicitPrompt: \'testx\',\\n        aiService: \'vertex-ai\',\\n      }),\\n    );\\n\\n    expect(vertexAi.generateContent).toHaveBeenCalledTimes(1);\\n    expect(result).toEqual(mockUnexpectedResponse);\\n  });\\n\\n  describe(\'validateAndRecoverSingleResult\', () => {\\n    it(\'should successfully recover from an invalid function call\', async () => {\\n      vi.mocked(cliParams).aiService = \'vertex-ai\';\\n      const mockInvalidCall = [\\n        {\\n          name: \'codegenSummary\',\\n          args: {\\n            files: [{ filePath: \'/mocked/root/dir/test.js\', updateToolName: \'updateFile\' }],\\n            contextPaths: [],\\n            explanation: \'Mock summary\',\\n          },\\n        },\\n      ];\\n      const mockValidCall = [\\n        {\\n          name: \'codegenSummary\',\\n          args: {\\n            fileUpdates: [\\n              { filePath: \'/mocked/root/dir/test.js\', updateToolName: \'updateFile\', prompt: \'Generate file\' },\\n            ],\\n            contextPaths: [],\\n            explanation: \'Mock summary\',\\n          },\\n        },\\n      ];\\n\\n      vi.mocked(vertexAi.generateContent)\\n        .mockResolvedValueOnce(mockInvalidCall)\\n        .mockResolvedValueOnce(mockValidCall)\\n        .mockResolvedValueOnce([\\n          {\\n            name: \'updateFile\',\\n            args: {\\n              filePath: \'/mocked/root/dir/test.js\',\\n              newContent: \'console.log(\\"Unexpected response\\");\',\\n            },\\n          },\\n        ]);\\n\\n      const result = await promptService(\\n        GENERATE_CONTENT_FNS,\\n        GENERATE_IMAGE_FNS,\\n        getCodeGenPrompt({\\n          askQuestion: false,\\n          disableContextOptimization: true,\\n          explicitPrompt: \'testx\',\\n          aiService: \'vertex-ai\',\\n        }),\\n      );\\n\\n      expect(vertexAi.generateContent).toHaveBeenCalledTimes(3);\\n      expect(result).toEqual([\\n        {\\n          args: {\\n            filePath: \'/mocked/root/dir/test.js\',\\n            newContent: \'console.log(\\"Unexpected response\\");\',\\n          },\\n          name: \'updateFile\',\\n        },\\n      ]);\\n    });\\n\\n    it(\'should handle unsuccessful recovery\', async () => {\\n      vi.mocked(cliParams).aiService = \'vertex-ai\';\\n      const mockInvalidCall = [\\n        {\\n          name: \'updateFile\',\\n          args: { filePath: \'/mocked/root/dir/test.js\', invalidArg: \'This should not be here\' },\\n        },\\n      ];\\n\\n      vi.mocked(vertexAi.generateContent)\\n        .mockResolvedValueOnce([\\n          {\\n            name: \'codegenSummary\',\\n            args: {\\n              fileUpdates: [\\n                { filePath: \'/mocked/root/dir/test.js\', updateToolName: \'patchFile\', prompt: \'Generate file\' },\\n              ],\\n              contextPaths: [],\\n              explanation: \'Mock summary\',\\n            },\\n          },\\n        ])\\n        .mockResolvedValueOnce(mockInvalidCall)\\n        .mockResolvedValueOnce(mockInvalidCall)\\n        .mockResolvedValueOnce(mockInvalidCall); // Second call also returns invalid result\\n\\n      await expect(\\n        promptService(\\n          GENERATE_CONTENT_FNS,\\n          GENERATE_IMAGE_FNS,\\n          getCodeGenPrompt({\\n            askQuestion: false,\\n            disableContextOptimization: true,\\n            explicitPrompt: \'testx\',\\n            aiService: \'vertex-ai\',\\n          }),\\n        ),\\n      ).rejects.toThrow(\'Recovery failed\');\\n\\n      expect(vertexAi.generateContent).toHaveBeenCalledTimes(4);\\n    });\\n\\n    it(\'should not attempt recovery for multiple valid function calls\', async () => {\\n      vi.mocked(cliParams).aiService = \'vertex-ai\';\\n      const mockValidCalls = [\\n        {\\n          name: \'updateFile\',\\n          args: { filePath: \'test1.js\', newContent: \'console.log(\\"File 1\\");\' },\\n        },\\n        {\\n          name: \'updateFile\',\\n          args: { filePath: \'test2.js\', newContent: \'console.log(\\"File 2\\");\' },\\n        },\\n      ];\\n\\n      vi.mocked(vertexAi.generateContent).mockResolvedValueOnce(mockValidCalls);\\n\\n      const result = await promptService(\\n        GENERATE_CONTENT_FNS,\\n        GENERATE_IMAGE_FNS,\\n        getCodeGenPrompt({\\n          askQuestion: false,\\n          disableContextOptimization: true,\\n          explicitPrompt: \'testx\',\\n          aiService: \'vertex-ai\',\\n        }),\\n      );\\n\\n      expect(vertexAi.generateContent).toHaveBeenCalledTimes(1);\\n      expect(result).toEqual(mockValidCalls);\\n    });\\n  });\\n});\\n"},"prompt-service.ts":{"content":"import assert from \'node:assert\';\\nimport fs from \'fs\';\\nimport mime from \'mime-types\';\\n\\nimport { getSystemPrompt } from \'./systemprompt.js\';\\nimport { getFunctionDefs } from \'./function-calling.js\';\\nimport { getSourceCode, getImageAssets } from \'../files/read-files.js\';\\nimport {\\n  PromptItem,\\n  FunctionDef,\\n  FunctionCall,\\n  GenerateContentFunction,\\n  GenerateImageFunction,\\n} from \'../ai-service/common.js\';\\nimport { importantContext } from \'../main/config.js\';\\nimport { AiServiceType, CodegenOptions, ImagenType } from \'../main/codegen-types.js\';\\nimport { executeStepAskQuestion } from \'./steps/step-ask-question/step-ask-question.js\';\\nimport { validateAndRecoverSingleResult } from \'./steps/step-validate-recover.js\';\\nimport { executeStepVerifyPatch } from \'./steps/step-verify-patch.js\';\\nimport { executeStepGenerateImage } from \'./steps/step-generate-image.js\';\\nimport { executeStepContextOptimization } from \'./steps/step-context-optimization.js\';\\nimport { StepResult } from \'./steps/steps-types.js\';\\nimport { CodegenPrompt } from \'./prompt-codegen.js\';\\nimport { putSystemMessage } from \'../main/common/content-bus.js\';\\nimport { handleAiServiceFallback } from \'./ai-service-fallback.js\';\\nimport { summarizeSourceCode } from \'./steps/step-summarization.js\';\\nimport { executeStepHistoryUpdate, getCurrentHistory } from \'./steps/step-history-update.js\';\\nimport { executeStepGenerateSummary } from \'./steps/step-generate-summary.js\';\\nimport { getSourceCodeTree } from \'../files/source-code-tree.js\';\\nimport {\\n  INITIAL_GREETING,\\n  REQUEST_SOURCE_CODE,\\n  SOURCE_CODE_RESPONSE,\\n  READY_TO_ASSIST,\\n  getPartialPromptTemplate,\\n} from \'./static-prompts.js\';\\nimport { executeStepCodegenPlanning } from \'./steps/step-codegen-planning.js\';\\nimport { getRegisteredGenerateContentHooks } from \'../main/plugin-loader.js\';\\n\\n/** A function that communicates with model using */\\nexport async function promptService(\\n  generateContentFns: Record<AiServiceType, GenerateContentFunction>,\\n  generateImageFns: Record<ImagenType, GenerateImageFunction>,\\n  codegenPrompt: CodegenPrompt,\\n  waitIfPaused: () => Promise<void> = () => Promise.resolve(),\\n): Promise<FunctionCall[]> {\\n  const generateContentFn: GenerateContentFunction = async (...args) => {\\n    // Get the base result from the AI service\\n    const result = await handleAiServiceFallback(\\n      generateContentFns,\\n      codegenPrompt.options.aiService,\\n      codegenPrompt.options,\\n      ...args,\\n    );\\n\\n    // Get registered hooks for the current AI service\\n    for (const hook of getRegisteredGenerateContentHooks()) {\\n      await hook(args, result);\\n    }\\n\\n    return result;\\n  };\\n\\n  const generateImageFn: GenerateImageFunction = (...args) => {\\n    assert(codegenPrompt.options.imagen, \'imagen value must be provided\');\\n    return generateImageFns[codegenPrompt.options.imagen](...args);\\n  };\\n\\n  const { result, prompt } = await executePromptService(\\n    generateContentFn,\\n    generateImageFn,\\n    codegenPrompt,\\n    waitIfPaused,\\n  );\\n\\n  if (codegenPrompt.options.historyEnabled) {\\n    await executeStepHistoryUpdate(generateContentFn, prompt, codegenPrompt.options);\\n  }\\n\\n  return result;\\n}\\n\\nasync function executePromptService(\\n  generateContentFn: GenerateContentFunction,\\n  generateImageFn: GenerateImageFunction,\\n  codegenPrompt: CodegenPrompt,\\n  waitIfPaused: () => Promise<void> = () => Promise.resolve(),\\n): Promise<{ result: FunctionCall[]; prompt: PromptItem[] }> {\\n  const messages = prepareMessages(codegenPrompt);\\n\\n  // First stage: summarize the source code\\n  if (!codegenPrompt.options.disableContextOptimization) {\\n    await summarizeSourceCode(\\n      generateContentFn,\\n      getSourceCode({ forceAll: true }, codegenPrompt.options),\\n      codegenPrompt.options,\\n    );\\n  }\\n\\n  // Second stage: generate code generation summary, which should not take a lot of output tokens\\n  const getSourceCodeRequest: FunctionCall = { name: \'getSourceCode\' };\\n\\n  const prompt: PromptItem[] = [\\n    { type: \'systemPrompt\', systemPrompt: getSystemPrompt(codegenPrompt.options) },\\n    { type: \'user\', text: INITIAL_GREETING },\\n    {\\n      type: \'assistant\',\\n      text: REQUEST_SOURCE_CODE,\\n      functionCalls: [\\n        getSourceCodeRequest,\\n        ...(codegenPrompt.options.vision ? [{ name: \'getImageAssets\' }] : []),\\n        ...(codegenPrompt.options.historyEnabled ? [{ name: \'readHistory\' }] : []),\\n      ],\\n    },\\n  ];\\n\\n  const getSourceCodeResponse: PromptItem = {\\n    type: \'user\',\\n    functionResponses: [\\n      { name: \'getSourceCode\', content: messages.sourceCode },\\n      ...(codegenPrompt.options.vision ? [{ name: \'getImageAssets\', content: messages.imageAssets }] : []),\\n      ...(codegenPrompt.options.historyEnabled ? [{ name: \'readHistory\', content: getCurrentHistory() }] : []),\\n    ],\\n    text: SOURCE_CODE_RESPONSE,\\n    cache: true,\\n  };\\n  prompt.push(getSourceCodeResponse);\\n\\n  prompt.push(\\n    {\\n      type: \'assistant\',\\n      text: READY_TO_ASSIST,\\n    },\\n    {\\n      type: \'user\',\\n      text: codegenPrompt.prompt,\\n    },\\n  );\\n\\n  // Add uploaded images to the prompt if available\\n  if (codegenPrompt.options.images && codegenPrompt.options.images.length > 0 && codegenPrompt.options.vision) {\\n    prompt.slice(-1)[0].images = codegenPrompt.options.images.map((img) => ({\\n      base64url: img.base64url,\\n      mediaType: img.mediaType,\\n    }));\\n  }\\n\\n  // Initial summary based on first user input\\n  await executeStepGenerateSummary(generateContentFn, prompt, codegenPrompt.options);\\n\\n  // Execute the context optimization step\\n  if (!codegenPrompt.options.disableContextOptimization) {\\n    const optimizationResult = await executeStepContextOptimization(generateContentFn, prompt, codegenPrompt.options);\\n\\n    if (optimizationResult === StepResult.BREAK) {\\n      return { result: [], prompt };\\n    }\\n  }\\n\\n  // Execute the ask question step\\n  if (codegenPrompt.options.askQuestion !== false && (codegenPrompt.options.interactive || codegenPrompt.options.ui)) {\\n    const askQuestionResult = await executeStepAskQuestion(\\n      generateContentFn,\\n      generateImageFn,\\n      prompt,\\n      getFunctionDefs(),\\n      codegenPrompt.options.temperature ?? 0.7,\\n      codegenPrompt.options,\\n    );\\n\\n    // Summary based on the ask-question conversation history (may be different from the initial summary)\\n    await executeStepGenerateSummary(generateContentFn, prompt, codegenPrompt.options);\\n\\n    if (askQuestionResult === StepResult.BREAK) {\\n      return { result: [], prompt };\\n    }\\n  } else if (codegenPrompt.options.askQuestion === false) {\\n    console.log(\'Ask question is not enabled.\');\\n    // Also there is no need to generate conversation summary\\n  }\\n\\n  const planningResult = await executeStepCodegenPlanning(generateContentFn, prompt, codegenPrompt.options);\\n  if (planningResult === StepResult.BREAK) {\\n    return { result: [], prompt };\\n  }\\n\\n  const baseRequest: [PromptItem[], FunctionDef[], string, number, boolean, CodegenOptions] = [\\n    prompt,\\n    getFunctionDefs(),\\n    \'codegenSummary\',\\n    codegenPrompt.options.temperature ?? 0.7,\\n    codegenPrompt.options.cheap ?? false,\\n    codegenPrompt.options,\\n  ];\\n  let baseResult = await generateContentFn(...baseRequest);\\n\\n  let codegenSummaryRequest = baseResult.find((call) => call.name === \'codegenSummary\');\\n\\n  if (codegenSummaryRequest) {\\n    // Second stage: for each file request the actual code updates\\n    putSystemMessage(\'Received codegen summary, will collect partial updates\', codegenSummaryRequest.args);\\n\\n    baseResult = await validateAndRecoverSingleResult(baseRequest, baseResult, generateContentFn);\\n    codegenSummaryRequest = baseResult.find((call) => call.name === \'codegenSummary\');\\n\\n    // Sometimes the result happens to be a string\\n    assert(Array.isArray(codegenSummaryRequest?.args?.fileUpdates), \'fileUpdates is not an array\');\\n    assert(Array.isArray(codegenSummaryRequest?.args.contextPaths), \'contextPaths is not an array\');\\n\\n    if (!codegenPrompt.options.disableContextOptimization) {\\n      console.log(\'Optimize with context paths.\');\\n      // Monkey patch the initial getSourceCode, do not send parts of source code that are consider irrelevant\\n      getSourceCodeRequest.args = {\\n        filePaths: [\\n          ...codegenSummaryRequest.args.fileUpdates.map((file: { filePath: string }) => file.filePath),\\n          ...codegenSummaryRequest.args.contextPaths,\\n          ...(importantContext.files ?? []),\\n        ],\\n      };\\n      getSourceCodeResponse.functionResponses!.find((item) => item.name === \'getSourceCode\')!.content =\\n        messages.contextSourceCode(getSourceCodeRequest.args?.filePaths as string[]);\\n    }\\n\\n    // Store the first stage response entirely in conversation history\\n    prompt.push({ type: \'assistant\', functionCalls: baseResult });\\n    prompt.push({\\n      type: \'user\',\\n      functionResponses: baseResult.map((call) => ({ name: call.name, call_id: call.id })),\\n      cache: true,\\n    });\\n\\n    const result: FunctionCall[] = [];\\n\\n    for (const file of codegenSummaryRequest!.args.fileUpdates) {\\n      putSystemMessage(\'Collecting partial update for: \' + file.filePath + \' using tool: \' + file.updateToolName, file);\\n\\n      // Check if execution is paused before proceeding\\n      await waitIfPaused();\\n\\n      // this is needed, otherwise we will get an error\\n      if (prompt.slice(-1)[0].type === \'user\') {\\n        prompt.slice(-1)[0].text = file.prompt ?? getPartialPromptTemplate(file.filePath);\\n      } else {\\n        prompt.push({ type: \'user\', text: file.prompt ?? getPartialPromptTemplate(file.filePath) });\\n      }\\n\\n      if (codegenPrompt.options.vision && file.contextImageAssets) {\\n        prompt.slice(-1)[0].images = file.contextImageAssets.map((path: string) => ({\\n          path,\\n          base64url: fs.readFileSync(path, \'base64\'),\\n          mediaType: mime.lookup(path) || \'\',\\n        }));\\n      }\\n\\n      const partialRequest: [PromptItem[], FunctionDef[], string, number, boolean, CodegenOptions] = [\\n        prompt,\\n        getFunctionDefs(),\\n        file.updateToolName,\\n        file.temperature ?? codegenPrompt.options.temperature,\\n        file.cheap === true,\\n        codegenPrompt.options,\\n      ];\\n      let partialResult = await generateContentFn(...partialRequest);\\n\\n      putSystemMessage(\'Received partial update\', partialResult);\\n\\n      // Validate if function call is compliant with the schema\\n      partialResult = await validateAndRecoverSingleResult(partialRequest, partialResult, generateContentFn);\\n\\n      // Handle image generation requests\\n      const generateImageCall = partialResult.find((call) => call.name === \'generateImage\');\\n      if (generateImageCall) {\\n        partialResult.push(await executeStepGenerateImage(generateImageFn, generateImageCall));\\n      }\\n\\n      // Verify if patchFile is one of the functions called, and test if patch is valid and can be applied successfully\\n      const patchFileCall = partialResult.find((call) => call.name === \'patchFile\');\\n      if (patchFileCall) {\\n        partialResult = await executeStepVerifyPatch(\\n          patchFileCall.args as { filePath: string; patch: string },\\n          generateContentFn,\\n          prompt,\\n          getFunctionDefs(),\\n          file.temperature ?? codegenPrompt.options.temperature,\\n          file.cheap === true,\\n          codegenPrompt.options,\\n        );\\n      }\\n\\n      // add the code gen result to the context, as the subsequent code gen may depend on the result\\n      prompt.push(\\n        { type: \'assistant\', functionCalls: partialResult },\\n        {\\n          type: \'user\',\\n          text: \'Update applied.\',\\n          functionResponses: partialResult.map((call) => ({ name: call.name, call_id: call.id })),\\n        },\\n      );\\n\\n      result.push(...partialResult);\\n    }\\n\\n    return { result, prompt };\\n  } else {\\n    // This is unexpected, if happens probably means no code updates.\\n    putSystemMessage(\'Did not receive codegen summary, returning result.\');\\n    return { result: baseResult, prompt };\\n  }\\n}\\n\\n/**\\n * Function to prepare messages for AI services\\n */\\nfunction prepareMessages(codegen: CodegenPrompt) {\\n  return {\\n    sourceCode: JSON.stringify(\\n      getSourceCodeTree(getSourceCode({ taskFile: codegen.options.taskFile }, codegen.options)),\\n    ),\\n    contextSourceCode: (paths: string[], pathsOnly: boolean = false) =>\\n      JSON.stringify(\\n        getSourceCodeTree(\\n          Object.fromEntries(\\n            Object.entries(\\n              getSourceCode(\\n                { filterPaths: paths, taskFile: codegen.options.taskFile, forceAll: true },\\n                codegen.options,\\n              ),\\n            ).filter(([path]) => !pathsOnly || paths.includes(path)),\\n          ),\\n        ),\\n      ),\\n    imageAssets: JSON.stringify(getImageAssets()),\\n  };\\n}\\n"},"static-prompts.ts":{"summary":"This file contains static prompts used in the prompt-service module, such as the initial greeting, request for source code, and acknowledgment of readiness to assist."},"systemprompt.test.ts":{"summary":"Unit tests for system prompt generation"},"systemprompt.ts":{"summary":"Generates the system prompt with guidelines and permissions for the code generation assistant."},"token-estimator.ts":{"summary":"Estimates token count for text and code"}},"/Users/gtanczyk/src/codegen/src/prompt/function-defs":{"ask-question.ts":{"content":"import { FunctionDef } from \'../../ai-service/common\';\\nimport { getRegisteredActionHandlerDescriptions, getRegisteredActionHandlers } from \'../../main/plugin-loader.js\';\\n\\nfunction getActionTypeDescription(): string {\\n  const pluginDescriptions = Array.from(getRegisteredActionHandlerDescriptions().entries())\\n    .map(([actionType, description]) => ` - ${actionType}: ${description}`)\\n    .join(\'\\\\n\');\\n\\n  return `This value instructs the program on what should happen next.\\n\\nDetailed Explanation of actionTypes:\\n- sendMessage: Use for general information, clarifications, or when no specific code is needed.\\n- sendMessageWithImage: Use when an image is needed to provide context or additional information.\\n- requestPermissions: Use **only when you lack necessary permissions** for actions like creating, deleting, or moving files, and need to request them from the user.\\n- requestFilesContent: Use specifically when needing to access or review the contents of files, and it was not provided yet in any of preceeding \\\\`getSourceCode\\\\` function responses.\\n- removeFilesFromContext: Use to remove unnecessary file contents from context, optimizing token usage.\\n- confirmCodeGeneration: Use to confirm with the user before starting code generation tasks.\\n- cancelCodeGeneration: Use to stop the session, and the conversation.\\n- contextOptimization: Use to manage and optimize context during code generation tasks, allowing the LLM to provide guidance on what parts of the context are most relevant to keep.\\n${pluginDescriptions}`;\\n}\\n\\n/**\\n * Function definition for askQuestion\\n *\\n * Use this function to ask questions, seek clarification, request file permissions, or manage the flow of the conversation.\\n * Each actionType serves a specific purpose, ensuring clarity and proper task execution.\\n */\\nexport const getAskQuestionDef = (): FunctionDef => ({\\n  name: \'askQuestion\',\\n  description: `Use this function to interact with the user for various purposes.\\n  The \\\\`decisionMakingProcess\\\\` must be provided as first parameter to ensure clarity in decision-making, and impact on selection of \\\\`actionType\\\\` and \\\\`message\\\\`.\\n  The \\\\`message\\\\` property must align with the chosen \\\\`actionType\\\\`.\\n  \\n  The desired format of parameters is as follows:\\n  \\\\`\\\\`\\\\`\\n  {\\n    \\"decisionMakingProcess\\": \\"...\\", // A detailed decision-making framework the assistant followed before selecting an action.\\",\\n    \\"actionType\\": \\"...\\", // The type of action to perform.\\n    \\"message\\": \\"...\\" // The message to display to the user.\\n  }\\n  \\\\`\\\\`\\\\`\\n  \\n  **IMPORTANT**: Mind the order of the parameters, as the decision-making process must be provided first to ensure clarity in decision-making.\\n  `,\\n  parameters: {\\n    type: \'object\',\\n    properties: {\\n      decisionMakingProcess: {\\n        type: \'string\',\\n        description: `A detailed decision-making framework the assistant followed before selecting an action. You must think step about step about this, this process should include the following steps:\\n\\n1. **Contextual Analysis**: Assess the current information, including available permissions, current context, and task requirements. Identify any missing elements that are critical to task completion.\\n\\n2. **Decision Justification**: State the reasoning for the proposed action, considering whether planning, clarification, or action is required. If there\'s any ambiguity, prefer a confirmatory action (\\\\`confirmCodeGeneration\\\\`).\\n\\n3. **Minimal Action Selection**: Determine the minimal action that can make progress toward the task goal. Avoid requesting unnecessary permissions or context that isn\'t strictly needed.\\n\\n4. **Evaluation of Action Choice**: Double-check if the selected action aligns with task requirements and user-provided constraints.\\n\\nOutput this in step-by-step format to ensure clarity in decision-making.`,\\n      },\\n      actionType: {\\n        type: \'string\',\\n        enum: [\\n          \'sendMessage\',\\n          \'sendMessageWithImage\',\\n          \'requestPermissions\',\\n          \'requestFilesContent\',\\n          \'removeFilesFromContext\',\\n          \'confirmCodeGeneration\',\\n          \'cancelCodeGeneration\',\\n          \'contextOptimization\',\\n          ...Array.from(getRegisteredActionHandlers().keys()),\\n        ],\\n        description: getActionTypeDescription(),\\n      },\\n      message: {\\n        type: \'string\',\\n        description: \'The message to display to the user.\',\\n      },\\n    },\\n    required: [\'decisionMakingProcess\', \'actionType\', \'message\'],\\n  },\\n});\\n\\n// requestFilesContent\\nexport const requestFilesContent: FunctionDef = {\\n  name: \'requestFilesContent\',\\n  description: \'Use this function to request the content of files that are missing from the context.\',\\n  parameters: {\\n    type: \'object\',\\n    properties: {\\n      filePaths: {\\n        type: \'array\',\\n        items: {\\n          type: \'string\',\\n        },\\n        description: \'An array of absolute file paths for which you need the content.\',\\n      },\\n    },\\n    required: [\'filePaths\'],\\n  },\\n};\\n\\n// sendMessageWithImage\\nexport const sendMessageWithImage: FunctionDef = {\\n  name: \'sendMessageWithImage\',\\n  description:\\n    \'Use this function to send message to the user with accompanying image that will be generated using provided prompt, and optionally using other image as a context.\',\\n  parameters: {\\n    type: \'object\',\\n    properties: {\\n      prompt: {\\n        type: \'string\',\\n        description: \'The prompt used to generate the image.\',\\n      },\\n      contextImage: {\\n        type: \'string\',\\n        description: \'Optional path to an image file used as context for image generation.\',\\n      },\\n    },\\n    required: [\'prompt\'],\\n  },\\n};\\n\\n// removeFilesFromContext\\nexport const removeFilesFromContext: FunctionDef = {\\n  name: \'removeFilesFromContext\',\\n  description: \'Use this function to remove files from the context that are no longer needed for code generation.\',\\n  parameters: {\\n    type: \'object\',\\n    properties: {\\n      filePaths: {\\n        type: \'array\',\\n        items: {\\n          type: \'string\',\\n        },\\n        description: \'An array of absolute file paths to remove from the context.\',\\n      },\\n    },\\n    required: [\'filePaths\'],\\n  },\\n};\\n\\n// contextOptimization\\nexport const contextOptimization: FunctionDef = {\\n  name: \'contextOptimization\',\\n  description:\\n    \'Use this function to optimize the context for code generation by specifying which parts are most relevant to keep.\',\\n  parameters: {\\n    type: \'object\',\\n    properties: {\\n      prompt: {\\n        type: \'string\',\\n        description: \'The prompt used to guide the user in optimizing the context.\',\\n      },\\n    },\\n    required: [\'prompt\'],\\n  },\\n};\\n\\n// requestPermissions\\nexport const requestPermissions: FunctionDef = {\\n  name: \'requestPermissions\',\\n  description: \'Use this function to request additional permissions needed for code generation if not already granted.\',\\n  parameters: {\\n    type: \'object\',\\n    properties: {\\n      allowDirectoryCreate: {\\n        description: \'Request permission to create directories.\',\\n        type: \'boolean\',\\n      },\\n      allowFileCreate: {\\n        description: \'Request permission to create files.\',\\n        type: \'boolean\',\\n      },\\n      allowFileDelete: {\\n        description: \'Request permission to delete files.\',\\n        type: \'boolean\',\\n      },\\n      allowFileMove: {\\n        description: \'Request permission to move files.\',\\n        type: \'boolean\',\\n      },\\n      enableVision: {\\n        description: \'Request permission for vision capabilities, using images as context for code generation.\',\\n        type: \'boolean\',\\n      },\\n      enableImagen: {\\n        description: \'Request permission to generate images.\',\\n        type: \'boolean\',\\n      },\\n    },\\n    required: [\\n      \'allowDirectoryCreate\',\\n      \'allowFileCreate\',\\n      \'allowFileDelete\',\\n      \'allowFileMove\',\\n      \'enableVision\',\\n      \'enableImagen\',\\n    ],\\n  },\\n};\\n"},"codegen-planning.ts":{"summary":"This file defines the function definition for the codegenPlanning function, which analyzes the conversation and produces a detailed implementation plan before proceeding with code generation."},"codegen-summary.ts":{"summary":"Definition of codegenSummary function"},"explanation.ts":{"summary":"Defines function to explain the reasoning behind code changes."},"generate-image.ts":{"summary":"Defines function to generate images using AI service."},"get-image-assets.ts":{"summary":"Defines function to get a map of application image assets."},"get-source-code.ts":{"summary":"Defines function definition for getSourceCode."},"optimize-context.ts":{"summary":"Defines optimizeContext function: prioritizes code files based on relevance to user prompt."},"read-history.ts":{"summary":"Defines function to read the conversation history."},"set-summaries.ts":{"summary":"Defines function to save summaries of files."},"update-history.ts":{"summary":"Defines function to update the conversation history."}},"/Users/gtanczyk/src/codegen/src/prompt/steps/step-ask-question/handlers":{"cancel-code-generation.ts":{"summary":"Handles cancellation of code generation"},"confirm-code-generation.ts":{"summary":"Handles user confirmation for starting code generation."},"context-optimization.ts":{"summary":"Handles user confirmation for optimizing context during code generation."},"default-action.ts":{"summary":"Default action handler"},"handle-send-message-with-image.ts":{"summary":"Handles sending message with generated image."},"handle-send-message.ts":{"summary":"Handles sending message without image."},"remove-files-from-context.ts":{"summary":"Handles removing files from context"},"request-files-content.ts":{"summary":"Handles requests for file contents."},"request-permissions.ts":{"summary":"Handles requesting permissions from user"}},"/Users/gtanczyk/src/codegen/src/prompt/steps/step-ask-question":{"step-ask-question-types.ts":{"summary":"Types for the \'ask question\' step."},"step-ask-question.ts":{"content":"import {\\n  FunctionDef,\\n  GenerateContentFunction,\\n  GenerateContentArgs,\\n  PromptItem,\\n  GenerateImageFunction,\\n} from \'../../../ai-service/common.js\';\\nimport { StepResult } from \'../steps-types.js\';\\nimport { CodegenOptions } from \'../../../main/codegen-types.js\';\\nimport { putAssistantMessage, putSystemMessage, putUserMessage } from \'../../../main/common/content-bus.js\';\\nimport { abortController } from \'../../../main/interactive/codegen-worker.js\';\\nimport { validateAndRecoverSingleResult } from \'../step-validate-recover.js\';\\nimport { AskQuestionCall, ActionType, ActionHandler } from \'./step-ask-question-types.js\';\\nimport { handleRequestFilesContent } from \'./handlers/request-files-content.js\';\\nimport { handleContextOptimization } from \'./handlers/context-optimization.js\';\\nimport { handleRemoveFilesFromContext } from \'./handlers/remove-files-from-context.js\';\\nimport { handleRequestPermissions } from \'./handlers/request-permissions.js\';\\nimport { handleDefaultAction } from \'./handlers/default-action.js\';\\nimport { handleSendMessage } from \'./handlers/handle-send-message.js\';\\nimport { handleSendMessageWithImage } from \'./handlers/handle-send-message-with-image.js\';\\nimport { handleConfirmCodeGeneration } from \'./handlers/confirm-code-generation.js\';\\nimport { handleCancelCodeGeneration } from \'./handlers/cancel-code-generation.js\';\\nimport { getRegisteredActionHandlers } from \'../../../main/plugin-loader.js\';\\n\\nexport async function executeStepAskQuestion(\\n  generateContentFn: GenerateContentFunction,\\n  generateImageFn: GenerateImageFunction,\\n  prompt: PromptItem[],\\n  functionDefs: FunctionDef[],\\n  temperature: number,\\n  options: CodegenOptions,\\n): Promise<StepResult> {\\n  console.log(\'Allowing the assistant to ask a question...\');\\n\\n  while (!abortController?.signal.aborted) {\\n    try {\\n      const askQuestionCall = await getAskQuestionCall(generateContentFn, prompt, functionDefs, temperature, options);\\n\\n      if (!askQuestionCall) {\\n        break;\\n      }\\n\\n      console.log(\'Assistant asks:\', askQuestionCall.args);\\n      if (askQuestionCall.args?.message) {\\n        putAssistantMessage(askQuestionCall.args.message, askQuestionCall.args);\\n      }\\n\\n      const actionType = askQuestionCall.args?.actionType;\\n      if (actionType) {\\n        const actionHandler = getActionHandler(actionType);\\n        const result = await actionHandler({\\n          askQuestionCall,\\n          prompt,\\n          options,\\n          generateContentFn,\\n          generateImageFn,\\n        });\\n\\n        // This is important to display the content to the user interface (ui or interactive cli)\\n        putUserMessage(result.items.slice(-1)[0].user.text);\\n\\n        prompt.push(...result.items.map(({ assistant, user }) => [assistant, user]).flat());\\n\\n        if (result.breakLoop) {\\n          return result.stepResult;\\n        }\\n\\n        console.log(\'The question was answered\');\\n      } else {\\n        console.error(\'Invalid action type received\');\\n        break;\\n      }\\n    } catch (error) {\\n      console.error(\'Error in executeStepAskQuestion:\', error);\\n      putSystemMessage(`An error occurred: ${error instanceof Error ? error.message : String(error)}`);\\n      return StepResult.BREAK;\\n    }\\n  }\\n\\n  putSystemMessage(\'Assistant did not ask a question. This unexpected, we need to abort.\');\\n  return StepResult.BREAK;\\n}\\n\\nasync function getAskQuestionCall(\\n  generateContentFn: GenerateContentFunction,\\n  prompt: PromptItem[],\\n  functionDefs: FunctionDef[],\\n  temperature: number,\\n  options: CodegenOptions,\\n): Promise<AskQuestionCall | undefined> {\\n  const askQuestionRequest: GenerateContentArgs = [prompt, functionDefs, \'askQuestion\', temperature, true, options];\\n  let askQuestionResult = await generateContentFn(...askQuestionRequest);\\n  askQuestionResult = await validateAndRecoverSingleResult(askQuestionRequest, askQuestionResult, generateContentFn);\\n\\n  return askQuestionResult.find((call) => call.name === \'askQuestion\') as AskQuestionCall | undefined;\\n}\\n\\nfunction getActionHandler(actionType: ActionType): ActionHandler {\\n  // First, check if there\'s a plugin-provided handler for this action type\\n  const pluginHandler = getRegisteredActionHandlers().get(actionType as `plugin:${string}`);\\n  if (pluginHandler) {\\n    return pluginHandler;\\n  }\\n\\n  // If no plugin handler is found, use the built-in handlers\\n  const handlers: Record<ActionType, ActionHandler> = {\\n    cancelCodeGeneration: handleCancelCodeGeneration,\\n    confirmCodeGeneration: handleConfirmCodeGeneration,\\n    requestFilesContent: handleRequestFilesContent,\\n    requestPermissions: handleRequestPermissions,\\n    removeFilesFromContext: handleRemoveFilesFromContext,\\n    sendMessage: handleSendMessage,\\n    sendMessageWithImage: handleSendMessageWithImage,\\n    contextOptimization: handleContextOptimization,\\n  };\\n\\n  return handlers[actionType] || handleDefaultAction;\\n}\\n"}},"/Users/gtanczyk/src/codegen/src/prompt/steps":{"step-codegen-planning.ts":{"summary":"This file defines the logic for the codegen planning step, which analyzes the conversation and produces a detailed implementation plan before proceeding with code generation."},"step-context-optimization.test.ts":{"summary":"Unit tests for context optimization step."},"step-context-optimization.ts":{"summary":"Optimizes context for code generation by evaluating file relevance and token cost."},"step-generate-image.ts":{"summary":"Implements the step to generate images using AI service."},"step-generate-summary.ts":{"summary":"Implements the step to generate a summary of the conversation."},"step-history-update.ts":{"summary":"Implements the step to update the conversation history."},"step-summarization.ts":{"summary":"Summarizes source code files and caches the summaries."},"step-validate-recover.ts":{"content":"import assert from \'node:assert\';\\nimport { FunctionCall, GenerateContentFunction, GenerateContentArgs } from \'../../ai-service/common.js\';\\nimport { validateFunctionCall } from \'../function-calling-validate.js\';\\n\\nexport async function validateAndRecoverSingleResult(\\n  [prompt, functionDefs, requiredFunctionName, temperature, cheap, options]: GenerateContentArgs,\\n  result: FunctionCall[],\\n  generateContentFn: GenerateContentFunction,\\n): Promise<FunctionCall[]> {\\n  if (result.length > 1 || !requiredFunctionName) {\\n    // quite unexpected\\n    return result;\\n  }\\n\\n  let call: FunctionCall | undefined = result[0];\\n  const validatorError = validateFunctionCall(call, requiredFunctionName);\\n  if (validatorError) {\\n    console.log(\'Invalid function call\', call, validatorError);\\n    if (!call) {\\n      call = { name: requiredFunctionName };\\n      if (requiredFunctionName === \'patchFile\') {\\n        console.log(\'Switching patchFile to updateFile\');\\n        requiredFunctionName = \'updateFile\';\\n      }\\n    }\\n\\n    prompt = [\\n      ...prompt,\\n      { type: \'assistant\', functionCalls: [call] },\\n      {\\n        type: \'user\',\\n        text: \'Function call was invalid, please analyze the error and respond with corrected function call.\',\\n        functionResponses: [\\n          {\\n            name: call.name,\\n            call_id: call.id,\\n            content: JSON.stringify({ args: call.args, error: validatorError }),\\n            isError: true,\\n          },\\n        ],\\n      },\\n    ];\\n\\n    console.log(\'Trying to recover...\');\\n    if (cheap) {\\n      console.log(\'Disabling --cheap for recovery.\');\\n    }\\n    result = await generateContentFn(prompt, functionDefs, requiredFunctionName, temperature, true, options);\\n    console.log(\'Recover result:\', result);\\n\\n    if (result?.length === 1) {\\n      let recoveryError = validateFunctionCall(result[0], requiredFunctionName);\\n      if (recoveryError) {\\n        console.log(\\"Use more expensive recovery method, because we couldn\'t recover.\\");\\n        result = await generateContentFn(prompt, functionDefs, requiredFunctionName, temperature, false, options);\\n        recoveryError = validateFunctionCall(result?.[0], requiredFunctionName);\\n        assert(!recoveryError, \'Recovery failed\');\\n      }\\n      console.log(\'Recovery was successful\');\\n    } else if (result?.length === 0) {\\n      throw new Error(\'Did not receive any function calls unexpectedly.\');\\n    } else {\\n      console.log(\'Unexpected number of function calls\', result);\\n    }\\n  }\\n\\n  return result;\\n}\\n"},"step-verify-patch.ts":{"summary":"Implements the step to verify the validity of a patch file."},"steps-types.ts":{"summary":"Defines types for the prompt service steps."},"steps-utils.ts":{"summary":"Provides utility functions for the prompt service steps."}},"/Users/gtanczyk/src/codegen/src/vite-genaicode":{"README.md":{"summary":"Docs for Vite plugin that integrates GenAIcode into dev workflow."},"tsconfig.json":{"summary":"TypeScript config for Vite GenAIcode plugin."},"vite-env.d.ts":{"summary":"TypeScript type definitions for Vite environment."},"vite-genaicode-frontend.ts":{"summary":"Custom element for GenAICode overlay in Vite plugin."},"vite-genaicode-plugin.ts":{"summary":"Vite plugin for GenAIcode"}}}',
      },
      {
        name: 'getImageAssets',
        content:
          '{"/Users/gtanczyk/src/codegen/media/logo-dark.png":{"mimeType":"image/png","width":1200,"height":686},"/Users/gtanczyk/src/codegen/media/logo.png":{"mimeType":"image/png","width":1200,"height":686},"/Users/gtanczyk/src/codegen/src/vite-genaicode/media/demo-for-readme.gif":{"mimeType":"image/gif","width":769,"height":465}}',
      },
      {
        name: 'readHistory',
        content:
          '2024-11-02T22:24: Upd Plugin type, plugin-loader, prompt-srv for generateContent hooks. Ex impl in nonsense_op plugin. 17:29: Upd img gen/ctx handl, verf prompt-srv. 17:26: Img gen UI, no ctx. Upd: handle-send-msg-img.ts, prompt-srv.ts. 17:22: Img gen/save req. 17:02: AI srv sel, prompt-srv upd. 12:37: codegenPlanning intro. 12:08: codegen artifacts upd. 11-01: self-reflect upd. 10: opt opts, ctx retain. 29: step-ctx-opt tst. 28: getSourceCodeTree, summ gen. 22: plugin ActionTypes.',
      },
    ],
    text: 'Sure, here is the application source code, image assets, and the history.',
    cache: true,
  },
  {
    type: 'assistant',
    text: "Thank you, I'm ready to assist you with your request.",
  },
  {
    type: 'user',
    text: 'we need to fix failing tests in prompt-service.test.ts',
  },
  {
    type: 'assistant',
    text: 'To better understand the issue, I would like to request the content of the prompt-service.test.ts file. This will help me analyze the test cases and identify the root cause of the failures.',
    functionCalls: [
      {
        name: 'requestFilesContent',
        args: {
          filePaths: ['/Users/gtanczyk/src/codegen/src/prompt/prompt-service.test.ts'],
        },
      },
    ],
  },
  {
    type: 'user',
    // text: 'You already have the content of /Users/gtanczyk/src/codegen/src/prompt/prompt-service.test.ts.',
    functionResponses: [{ name: 'requestFilesContent' }],
  },
  // {
  //   type: 'assistant',
  //   text: 'Okay, great. I have the content of the prompt-service.test.ts file, so I can proceed with analyzing the test cases and identifying the root cause of the failures. I will review the test cases and propose a plan to fix the failing tests.',
  // },
  // {
  //   type: 'user',
  //   text: 'Ok',
  // },
];
